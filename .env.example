# =============================================================================
# JOB PIPELINE CONFIGURATION
# =============================================================================
# This file shows the configuration structure for the job pipeline.
# 
# IMPORTANT: Sensitive values (API keys, passwords) should be stored in 
# AWS Secrets Manager, not in this .env file!
#
# See: https://docs.aws.amazon.com/secretsmanager/
# =============================================================================

# =============================================================================
# AWS SECRETS MANAGER CONFIGURATION
# =============================================================================
# These settings tell the application where to find your secrets
AWS_SECRETS_NAME=job-pipeline/secrets
AWS_REGION=eu-west-2

# =============================================================================
# NON-SENSITIVE CONFIGURATION
# =============================================================================
# These values are safe to store in .env files

# Database connection settings (non-sensitive)
BD_HOST=brd.superproxy.io
BD_PORT=33335
BD_COUNTRY=gb

# Logging configuration
LOG_LEVEL=INFO
LOG_APP_NAME=job_pipeline
DISABLE_FILE_LOGGING=true

# Storage configuration
USE_S3=true
S3_BUCKET_NAME=job-analysis-test
S3_REGION=eu-west-2

# Data directories (optional, defaults to project/data)
# For local development:
# DATA_DIR=/home/kyryl/dev/market_analysis/data
# LOGS_DIR=/home/kyryl/dev/market_analysis/logs

# For Docker/containerized deployment:
# DATA_DIR=/app/data
# LOGS_DIR=/app/logs

# Python path for development
# PYTHONPATH=/app/src

# =============================================================================
# PIPELINE RUNTIME CONFIGURATION
# =============================================================================
# These can be used for on-demand runs and scheduled tasks

# Preset to use (overrides CLI --preset if not provided)
# PIPELINE_PRESET=data_scientist_gb

# Run name for output files (overrides CLI --name if not provided)
# PIPELINE_RUN_NAME=scheduled_run_20241201_143000

# Concurrency level (overrides preset max_workers and CLI --concurrency if not provided)
# PIPELINE_CONCURRENCY=50

# Custom search parameters as JSON (overrides CLI --kwargs if not provided)
# PIPELINE_SEARCH_KWARGS={"country":"gb","what_and":"python","scope":"single_page","page":1}

# =============================================================================
# SENSITIVE VALUES (STORE IN AWS SECRETS MANAGER)
# =============================================================================
# DO NOT PUT THESE IN YOUR .env FILE!
# Store these in AWS Secrets Manager with the name specified in AWS_SECRETS_NAME
#
# The following values should be stored in AWS Secrets Manager:
# - ADZUNA_ID
# - ADZUNA_KEY  
# - BD_USERNAME_BASE
# - BD_PASSWORD
# - AWS_ACCESS_KEY_ID
# - AWS_SECRET_ACCESS_KEY
#
# Example JSON for AWS Secrets Manager:
# {
#   "ADZUNA_ID": "your_adzuna_id_here",
#   "ADZUNA_KEY": "your_adzuna_key_here",
#   "BD_USERNAME_BASE": "your_db_username_here",
#   "BD_PASSWORD": "your_db_password_here",
#   "AWS_ACCESS_KEY_ID": "your_aws_access_key_here",
#   "AWS_SECRET_ACCESS_KEY": "your_aws_secret_key_here"
# }
# =============================================================================